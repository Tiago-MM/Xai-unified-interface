{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9275110d",
   "metadata": {},
   "source": [
    "# Training of AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0466c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dad6996a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 6\n",
    "\n",
    "DATA_DIR = \"../dataset_grayscale\"\n",
    "CLASSES = [\"Normal\", \"Lung Opacity\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "840804c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label, cls in enumerate(CLASSES):\n",
    "    class_dir = os.path.join(DATA_DIR, cls)\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            path = os.path.join(class_dir, file)\n",
    "            img = Image.open(path)\n",
    "            img = img.resize((IMG_SIZE, IMG_SIZE))\n",
    "            img = np.array(img) / 255.0\n",
    "            img = np.expand_dims(img, axis=-1)  # canal unique\n",
    "            images.append(img)\n",
    "            labels.append(label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "435ad258",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images, dtype=np.float32)\n",
    "labels = np.array(labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ddaa3ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1662, 224, 224, 1)\n",
      "Val: (356, 224, 224, 1)\n",
      "Test: (357, 224, 224, 1)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(images))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# split\n",
    "total = len(images)\n",
    "train_size = int(0.7 * total)\n",
    "val_size   = int(0.15 * total)\n",
    "\n",
    "# train, val, test\n",
    "x_train = images[:train_size]\n",
    "y_train = labels[:train_size]\n",
    "x_val   = images[train_size:train_size+val_size]\n",
    "y_val   = labels[train_size:train_size+val_size]\n",
    "x_test  = images[train_size+val_size:]\n",
    "y_test  = labels[train_size+val_size:]\n",
    "\n",
    "print(\"Train:\", x_train.shape)\n",
    "print(\"Val:\", x_val.shape)\n",
    "print(\"Test:\", x_test.shape)\n",
    "\n",
    "# datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d0fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ALEXNET ARCHITECTURE\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 1)),\n",
    "\n",
    "    # Conv 1\n",
    "    keras.layers.Conv2D(96, 11, strides=4, activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    # Conv 2\n",
    "    keras.layers.Conv2D(256, 5, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    # Conv 3\n",
    "    keras.layers.Conv2D(384, 3, padding=\"same\", activation=\"relu\"),\n",
    "\n",
    "    # Conv 4\n",
    "    keras.layers.Conv2D(384, 3, padding=\"same\", activation=\"relu\"),\n",
    "\n",
    "    # Conv 5\n",
    "    keras.layers.Conv2D(256, 3, padding=\"same\", activation=\"relu\"),\n",
    "    keras.layers.MaxPooling2D(3, strides=2),\n",
    "\n",
    "    # Connected Layers\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(4096, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    # Output\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b324f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 54, 54, 96)        11712     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 26, 26, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 5, 5, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 6400)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              26218496  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 46727873 (178.25 MB)\n",
      "Trainable params: 46727873 (178.25 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compilation\n",
    "optimizer = keras.optimizers.legacy.Adam()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938ae48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "52/52 [==============================] - 59s 1s/step - loss: 0.6997 - accuracy: 0.5187 - auc: 0.5191 - val_loss: 0.6915 - val_accuracy: 0.5309 - val_auc: 0.6046\n",
      "Epoch 2/6\n",
      "52/52 [==============================] - 52s 998ms/step - loss: 0.6645 - accuracy: 0.5728 - auc: 0.6143 - val_loss: 0.5876 - val_accuracy: 0.7022 - val_auc: 0.8540\n",
      "Epoch 3/6\n",
      "52/52 [==============================] - 52s 1s/step - loss: 0.4888 - accuracy: 0.7804 - auc: 0.8483 - val_loss: 0.4507 - val_accuracy: 0.7921 - val_auc: 0.9052\n",
      "Epoch 4/6\n",
      "52/52 [==============================] - 52s 1s/step - loss: 0.4075 - accuracy: 0.8201 - auc: 0.8950 - val_loss: 0.3843 - val_accuracy: 0.8230 - val_auc: 0.9083\n",
      "Epoch 5/6\n",
      "52/52 [==============================] - 51s 985ms/step - loss: 0.3980 - accuracy: 0.8255 - auc: 0.9004 - val_loss: 0.3970 - val_accuracy: 0.8062 - val_auc: 0.9051\n",
      "Epoch 6/6\n",
      "52/52 [==============================] - 53s 1s/step - loss: 0.3908 - accuracy: 0.8321 - auc: 0.9052 - val_loss: 0.3903 - val_accuracy: 0.8118 - val_auc: 0.9089\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dae77db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 3s 255ms/step - loss: 0.3555 - accuracy: 0.8487 - auc: 0.9198\n",
      "Test Accuracy: 0.848739504814148\n",
      "Test AUC: 0.9198367595672607\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "loss, acc, auc = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(\"Test AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5f5fdea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 429ms/step\n",
      "1/1 [==============================] - 0s 300ms/step\n",
      "1/1 [==============================] - 0s 256ms/step\n",
      "1/1 [==============================] - 0s 266ms/step\n",
      "1/1 [==============================] - 0s 293ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 260ms/step\n",
      "1/1 [==============================] - 0s 271ms/step\n",
      "1/1 [==============================] - 0s 262ms/step\n",
      "1/1 [==============================] - 0s 356ms/step\n",
      "1/1 [==============================] - 0s 270ms/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "[[151  29]\n",
      " [ 25 152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.86      0.84      0.85       180\n",
      "Lung Opacity       0.84      0.86      0.85       177\n",
      "\n",
      "    accuracy                           0.85       357\n",
      "   macro avg       0.85      0.85      0.85       357\n",
      "weighted avg       0.85      0.85      0.85       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 18:43:57.155812: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# resukts\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for x, y in test_ds:\n",
    "    preds = model.predict(x)\n",
    "    preds = (preds > 0.5).astype(int)\n",
    "    y_true.extend(y.numpy())\n",
    "    y_pred.extend(preds.flatten())\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d563d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiago/Documents/esilvA5/ecole/ExplainAI/finprojet/Xai-unified-interface/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "script_dir = os.getcwd() \n",
    "model.save(os.path.join(script_dir, '..', '..', 'models', 'my_alexnet.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d192b6",
   "metadata": {},
   "source": [
    "# Densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689d7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "labels = []\n",
    "\n",
    "for label, cls in enumerate(CLASSES):\n",
    "    class_dir = os.path.join(DATA_DIR, cls)\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            path = os.path.join(class_dir, file)\n",
    "            img = Image.open(path).resize((IMG_SIZE, IMG_SIZE))\n",
    "            img = np.array(img) / 255.0\n",
    "            if img.ndim == 2:  # grayscale -> RGB\n",
    "                img = np.stack([img]*3, axis=-1)\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "images = np.array(images, dtype=np.float32)\n",
    "labels = np.array(labels, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42ebf4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (1662, 224, 224, 3)\n",
      "Val: (356, 224, 224, 3)\n",
      "Test: (357, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(len(images))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "images = images[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "# split\n",
    "total = len(images)\n",
    "train_size = int(0.7 * total)\n",
    "val_size   = int(0.15 * total)\n",
    "\n",
    "# train, val, test\n",
    "x_train = images[:train_size]\n",
    "y_train = labels[:train_size]\n",
    "x_val   = images[train_size:train_size+val_size]\n",
    "y_val   = labels[train_size:train_size+val_size]\n",
    "x_test  = images[train_size+val_size:]\n",
    "y_test  = labels[train_size+val_size:]\n",
    "\n",
    "print(\"Train:\", x_train.shape)\n",
    "print(\"Val:\", x_val.shape)\n",
    "print(\"Test:\", x_test.shape)\n",
    "\n",
    "# datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds   = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds  = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8ec6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = keras.applications.DenseNet121(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False,\n",
    "    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    ")\n",
    "base_model.trainable = False\n",
    "\n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0e73bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
      "                                                                 \n",
      " global_average_pooling2d_1  (None, 1024)              0         \n",
      "  (GlobalAveragePooling2D)                                       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               262400    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7300161 (27.85 MB)\n",
      "Trainable params: 262657 (1.00 MB)\n",
      "Non-trainable params: 7037504 (26.85 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compilation\n",
    "optimizer = keras.optimizers.legacy.Adam()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\")]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "055dcde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "52/52 [==============================] - 69s 1s/step - loss: 0.4627 - accuracy: 0.7918 - auc: 0.8687 - val_loss: 0.3569 - val_accuracy: 0.8483 - val_auc: 0.9238\n",
      "Epoch 2/6\n",
      "52/52 [==============================] - 78s 2s/step - loss: 0.3481 - accuracy: 0.8562 - auc: 0.9231 - val_loss: 0.3400 - val_accuracy: 0.8567 - val_auc: 0.9256\n",
      "Epoch 3/6\n",
      "52/52 [==============================] - 79s 2s/step - loss: 0.3258 - accuracy: 0.8694 - auc: 0.9327 - val_loss: 0.3189 - val_accuracy: 0.8596 - val_auc: 0.9350\n",
      "Epoch 4/6\n",
      "52/52 [==============================] - 79s 2s/step - loss: 0.3019 - accuracy: 0.8857 - auc: 0.9431 - val_loss: 0.3137 - val_accuracy: 0.8596 - val_auc: 0.9367\n",
      "Epoch 5/6\n",
      "52/52 [==============================] - 84s 2s/step - loss: 0.3027 - accuracy: 0.8767 - auc: 0.9414 - val_loss: 0.3144 - val_accuracy: 0.8567 - val_auc: 0.9369\n",
      "Epoch 6/6\n",
      "52/52 [==============================] - 85s 2s/step - loss: 0.2861 - accuracy: 0.8833 - auc: 0.9488 - val_loss: 0.3073 - val_accuracy: 0.8539 - val_auc: 0.9403\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41ec54f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 16s 1s/step - loss: 0.2758 - accuracy: 0.8824 - auc: 0.9534\n",
      "Test Accuracy: 0.8823529481887817\n",
      "Test AUC: 0.953405499458313\n"
     ]
    }
   ],
   "source": [
    "loss, acc, auc = model.evaluate(test_ds)\n",
    "print(\"Test Accuracy:\", acc)\n",
    "print(\"Test AUC:\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1b4d55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "[[163  17]\n",
      " [ 25 152]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.87      0.91      0.89       180\n",
      "Lung Opacity       0.90      0.86      0.88       177\n",
      "\n",
      "    accuracy                           0.88       357\n",
      "   macro avg       0.88      0.88      0.88       357\n",
      "weighted avg       0.88      0.88      0.88       357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-08 18:58:24.222396: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for x, y in test_ds:\n",
    "    preds = model.predict(x)\n",
    "    preds = (preds > 0.5).astype(int)\n",
    "    y_true.extend(y.numpy())\n",
    "    y_pred.extend(preds.flatten())\n",
    "\n",
    "print(confusion_matrix(y_true, y_pred))\n",
    "print(classification_report(y_true, y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7d8e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiago/Documents/esilvA5/ecole/ExplainAI/finprojet/Xai-unified-interface/venv/lib/python3.10/site-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(os.path.join(script_dir, '..', '..', 'models', 'my_densenet.h5'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
